{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492d80ce",
   "metadata": {},
   "source": [
    "#                      WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73dd172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122a03b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANSHUL~1\\AppData\\Local\\Temp/ipykernel_38612/530843676.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('chromedriver.exe')\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0071f709",
   "metadata": {},
   "source": [
    "# Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "1. First get the webpage https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "905be8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d791fc5",
   "metadata": {},
   "source": [
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f8c57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering details in search criteria for designations\n",
    "search_designation=driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_designation.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8a08be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_loc=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_loc.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d3c8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f4fb0b",
   "metadata": {},
   "source": [
    "4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d63331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "012ed273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting all the tages with the job titles.\n",
    "\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title_tags:\n",
    "    job_title.append(i.text)\n",
    "    Job=job_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbc6bc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business Data Analyst',\n",
       " 'EY GDS Data Analyst-Finland based project',\n",
       " 'Business & Data Analyst - Alteryx (London)',\n",
       " 'Data Analyst - Data and Analytics',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst - Data Science, 3 To 5 Years',\n",
       " 'Data Analyst / Business Analyst',\n",
       " 'Genpact Hiring For Data Analyst',\n",
       " 'data analyst/ data analytics / Business analyst- SQL/Python/SAS',\n",
       " 'Data analyst / Data scientist, AVP',\n",
       " 'Data analyst / Data scientist, Associate',\n",
       " 'Senior Mis Data Analyst',\n",
       " 'Junior Data Analyst/ Scientist- Fresher Position',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst ( Outsourced)',\n",
       " 'Master Data Management Business Analyst',\n",
       " 'Data Analytics and Interpretation Business Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01dec7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR\\n(WFH during Covid)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job location.\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "for i in location_tags:\n",
    "    job_location.append(i.text)\n",
    "    loc=job_location[:10]\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "893149d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NXP Semiconductors',\n",
       " 'EY',\n",
       " 'Imaginative Brains LLP',\n",
       " 'Intel',\n",
       " 'Flipkart',\n",
       " 'Walmart',\n",
       " 'Rise Finconnect Private Limited',\n",
       " 'METRO Cash & Carry',\n",
       " 'Genpact',\n",
       " 'Leading US MNC into Analytics']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the company names.\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company_tags:\n",
    "    company_name.append(i.text)\n",
    "    com=company_name[:10]\n",
    "com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea8aa739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-5 Yrs',\n",
       " '0-1 Yrs',\n",
       " '5-10 Yrs',\n",
       " '3-6 Yrs',\n",
       " '3-7 Yrs',\n",
       " '4-7 Yrs',\n",
       " '2-6 Yrs',\n",
       " '3-8 Yrs',\n",
       " '2-6 Yrs',\n",
       " '2-7 Yrs']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the experince required.\n",
    "exp_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for i in exp_tags:\n",
    "    experience_required.append(i.text)\n",
    "    exp=experience_required[:10]\n",
    "exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bca22e",
   "metadata": {},
   "source": [
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a49542d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>NXP Semiconductors</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EY GDS Data Analyst-Finland based project</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>EY</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Business &amp; Data Analyst - Alteryx (London)</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "      <td>Imaginative Brains LLP</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - Data and Analytics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Intel</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - Data Science, 3 To 5 Years</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rise Finconnect Private Limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Genpact Hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0                              Business Data Analyst   \n",
       "1          EY GDS Data Analyst-Finland based project   \n",
       "2         Business & Data Analyst - Alteryx (London)   \n",
       "3                  Data Analyst - Data and Analytics   \n",
       "4                                Senior Data Analyst   \n",
       "5                                Senior Data Analyst   \n",
       "6          Data Analyst - Data Science, 3 To 5 Years   \n",
       "7                    Data Analyst / Business Analyst   \n",
       "8                    Genpact Hiring For Data Analyst   \n",
       "9  data analyst/ data analytics / Business analys...   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...   \n",
       "\n",
       "                           Company Experience Required  \n",
       "0               NXP Semiconductors             2-5 Yrs  \n",
       "1                               EY             0-1 Yrs  \n",
       "2           Imaginative Brains LLP            5-10 Yrs  \n",
       "3                            Intel             3-6 Yrs  \n",
       "4                         Flipkart             3-7 Yrs  \n",
       "5                          Walmart             4-7 Yrs  \n",
       "6  Rise Finconnect Private Limited             2-6 Yrs  \n",
       "7               METRO Cash & Carry             3-8 Yrs  \n",
       "8                          Genpact             2-6 Yrs  \n",
       "9    Leading US MNC into Analytics             2-7 Yrs  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Analyst={'Job':Job,'Location':loc,\n",
    "              'Company':com,'Experience Required':exp}\n",
    "Data_Analyst=pd.DataFrame(data=Data_Analyst)\n",
    "Data_Analyst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcecaad",
   "metadata": {},
   "source": [
    "# Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0801989",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad982f",
   "metadata": {},
   "source": [
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1e1661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering details in search criteria for designations\n",
    "search_designation=driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_designation.send_keys('Data Scientist')\n",
    "\n",
    "#Entering deatils in loaction field\n",
    "search_location=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64c7e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac09256",
   "metadata": {},
   "source": [
    "4. Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "24f09431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "job=[]\n",
    "loc=[]\n",
    "comp=[]\n",
    "desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e63521e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AI Technologist Vacancy',\n",
       " 'Job Opening with Wipro For Data Scientist position',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - Immediate Joiners',\n",
       " 'Data Scientist- AI/ML- R&D',\n",
       " 'Urgent Hiring For AI Data Scientist']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job titles.\n",
    "\n",
    "title=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in title:\n",
    "    job.append(i.text)\n",
    "    job=job[:10]\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5c7191c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location=driver.find_element_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "location.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e588aff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kolkata, Hyderabad/Secunderabad, Pune, Ahmedabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Kolkata, Hyderabad/Secunderabad, Chennai, Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'Noida, Mumbai, Pune, Bangalore/Bengaluru',\n",
       " 'Noida, Hyderabad/Secunderabad, Pune, Gurgaon/Gurugram, Chennai, Bangalore/Bengaluru, Delhi / NCR',\n",
       " 'New Delhi, Bangalore/Bengaluru, Mumbai (All Areas)']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the job location.\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in locations:\n",
    "    loc.append(i.text)\n",
    "loc=loc[:10]\n",
    "loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b9fc224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wipro',\n",
       " 'Wipro',\n",
       " 'Genpact',\n",
       " 'Walmart',\n",
       " 'Walmart',\n",
       " 'Genpact',\n",
       " 'Genpact',\n",
       " 'Bristlecone',\n",
       " 'EXL',\n",
       " 'Ashkom Media India Private Limited']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting all the tages with the company names.\n",
    "company=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in company:\n",
    "    comp.append(i.text)\n",
    "    \n",
    "comp=comp[:10]\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc4e9e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Roles and Responsibilities\\n\\n\\nDesired Candidate Profile\\nExperience with one or more general purpose programming languages including but not limited to: Java, C/C++, Python or R.\\nExperience in Architecture and Design tools like UML and Framework like TensorFlow, Torch or Caffe.\\nStrong background in Deep Learning/RNN/LSTM, Reinforcement Learning, Natural Language Processing, Cognitive Search or Computer Vision.\\nStrong background in Cognitive Computing, Machine Learning or Artificial Intelligence.\\nExperience in handling data in the form of text, speech, image, video or live stream from IoT/ Sensors/ Web.\\n\\nPerks and Benefits',\n",
       " 'Greetings from Wipro !\\n\\nWe are hiring for Data Scientist looking for early joiners. Please find the below Job details\\n\\nMandatory Skills - Data Scientist , Python, AWS , IoT data , Google Maps API\\n\\nPrimary responsibility\\nMust have experience in developing data science models.\\nExperience using machine learning algorithms (e.g. Generalized Linear Models, Boosting, Decision Trees, Neural Networks, SVM, Bayesian Methods, time series models, etc.)\\nHands-on experience in using machine learning models for regression and classification problems.\\nHands on experience in unsupervised machine learning algorithms. Working knowledge of clustering techniques such has, centroid based clustering.\\nWorking experience with Cloud Computing Platforms such as AWS / IBM\\nStrong programming skills in python is a must. Working experience with pandas, numpy, matplotlib, sklearn\\nShould have experience in one or more full-time Data Science/ML roles\\nData Visualization techniques. Knowledge of visualization tools\\n\\nDesirable:\\n\\nExperience in Spark or other distributed computing frameworks.\\nUnderstanding of AWS Sagemaker / Google AutoML / IBM AutoAI\\nExperience in time-series/IoT data analytics e.g. data streaming from vehicle on-board IoT device data in time-series format that may comprise of GPS data, on-board sensors of the vehicle powertrain, body and chassis systems.\\nExposure to automotive systems, automobile basics, Controller Area Network protocol (CAN protocol) etc.\\nExperience working with remote team members\\nData Visualization tools such as Tableau, PowerBI etc.\\nWorking experience with Google Maps API.',\n",
       " 'NA',\n",
       " '  As a Senior Data Scientist for Walmart, you ll have the opportunity to:\\nDrive data-derived insights across a wide range of divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiatives\\nDirect the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals\\nUtilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights\\nBuild and train statistical models and machine learning algorithms\\nApply your semantic, natural language processing and understanding expertise where required\\nProductionize the models and make those available at scale\\nBuild and maintain end to end Machine Learning pipelines\\nBe comfortable with ambiguity and uncertainty and the eagerness to change the world in a huge way by being a self-motivated learner and builder\\nCommunicate recommendations to business partners and influencing future plans based on insights\\nPosition Requirements/ Qualifications\\nBachelors degree in Statistics, Mathematics, Computer Science or a related field and 6 years experience in an analytics/DS related field, or,\\nMasters degree in Statistics, Mathematics, Computer Science or a related field and 5 years experience in an analytics/DS related field.\\nHigh proficiency in data mining, modeling, validation and insight generation.\\nExcellent working knowledge of statistics, mathematics, machine learning, data mining, deep learning\\nHigh proficiency in coding including Python and SQL\\nExperience with databases (for example, DB2, Oracle, SQL Server)\\nExperience with Big Data technologies such as Pig, Hive and/or Spark\\nAbility to work with large data sets. Has sound understanding of big data technology stack\\nUnderstanding of cloud computing platforms and large-scale databases\\nProven ability to collaborate and work in teams\\nExcellent with communications and stakeholder engagement\\nData science publications in recognized platforms/journals\\nProven ability to work in agile mode on data science sprint projects\\nOur Ideal Candidate\\nYou are a technically strong and high performing individual with excellent communication skills, proven analytical skill set and strong customer focus. You stay updated with latest research and technology ideas, and have a passion to utilize innovative ways to solve problems. You are a good story-teller and able to simply articulate the intricacies of your models as well as explain your results clearly to stakeholders. You have industry knowledge of the retail space, with keen interest in keeping up to date on the latest happenings in this space.\\nAdditional Preferred Qualifications:\\nDomain Knowledge of one or more divisions in Retail\\nPublished papers or given talks in leading academic and research journals\\nPublished papers or given talks in Data Science Forums\\nHold data science related patents\\nExperience with data warehouse platforms\\nExperience with GPU/CUDA for computational efficiency',\n",
       " '  Drive data-derived insights across the wide range of retail divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiatives\\nDirect the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals\\nUtilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights\\nBuild and train statistical models and machine learning algorithms for replication for future projects\\nCommunicate recommendations to business partners and influencing future plans based on insights\\nPosition Requirements:\\nPlay a key role to solve complex problems, pivotal to Walmart s business and drive actionable insights from petabytes of data\\nUtilize product mindset to build, scale and deploy holistic data science products after successful prototyping\\nDemonstrate incremental solution approach with agile and flexible ability to overcome practical problems\\nLead small teams and participate in data science project teams by serving as the technical lead for project\\nPartner with senior team members to assess customer needs and define business questions\\nClearly articulate and present recommendations to business partners, and influence future plans based on insights\\nPartner and engage with associates in other regions for delivering best services to the customers around the globe\\nWork with customer centric mindset to deliver high quality business driven analytic solution\\nMentor peers and analysts across the division in analytical best practices\\nDrive innovation in approach, method, practices, process, outcome, delivery, or any component of end-to-end problem solving\\nPromote and support company policies, procedures, mission, values, and standards of ethics and integrity\\nOur Ideal Candidate\\nYou have a deep interest and passion for technology. You love writing and owning codes and enjoy working with people who will keep challenging you at every stage. You have strong problem solving, analytic, design, architecture, decision-making and communication skills.\\nYou are self-driven and motivated with the desire to work in a fast-paced, results-driven agile environment with varied responsibilities. You stay updated with latest research and technology ideas, and have a passion to utilize innovative ways to solve problems. You are a good story-teller and able to simply articulate the intricacies of your models as well as explain your results clearly to stakeholders. You have industry knowledge of the retail space, with keen interest in keeping up to date on the latest happenings in this space.\\nYour Qualifications\\nBachelors with > 10 years of relevant experience OR Masters with > 7 years of relevant experience OR PHD in Comp Science/Statistics/Mathematics with > 4 years of relevant experience\\nExperience in Analyzing the Complex Problems and translate it into data science algorithms\\nExperience in machine learning, supervised and unsupervised: Forecasting, Classification, Data/Text Mining, NLP, Decision Trees, Adaptive Decision Algorithms, Random Forest, Search Algorithms, Neural Networks, Deep Learning Algorithms\\nExperience in statistical learning: Predictive & Prescriptive Analytics, Web Analytics, Parametric and Non-parametric models, Regression, Time Series, Dynamic/Causal Model, Statistical Learning, Guided Decisions, Topic Modeling\\nExperience with big data analytics - identifying trends, patterns, and outliers in large volumes of data\\nLead role mentoring multiple Jr. Analysts on approach and results.\\nStrong Experience with one or more of Python and R\\nStrong Experience with big data platforms - Hadoop (Hive, Pig, Map Reduce, HQL, Scala)\\nExperience with Teradata, SQL and relational databases, data warehouse\\nShould be a fast learner and quickly adapt to new technologies.\\nPrefer individuals with High Ownership and commitment.\\nAbility to work with distributed teams in a collaborative and productive manner.\\nA self-motivated learner and builder with strong customer focus and obsession with quality',\n",
       " 'NA',\n",
       " 'NA',\n",
       " 'An avid technology enthusiast , Machine leaning methodology , Linear and hedonic regressions, random forest\\nML Model Must have Regression models, Random Forest, Boosting models . Good to have other advanced ML techniques knowledge SVM, Naive Bayes , KNN,\\nClustering techniques K means etc\\nAI Deep Learning Must have some exposure to NLP, Text mining . Good to have Deep Learning Model knowledge e.g. ANN, CNN, LSTM\\nKnowledge of SAS, R , python predictive analytics Data Modelling etc.\\nHands on with Advance Excel and SQL\\nSoft Skill should Good communication skills who can do the stakeholder management as well.\\nExcellent presentation skill\\nAutomotive domain experience preferred.',\n",
       " 'NA',\n",
       " 'Job Description\\nDevelop math models and algorithms and deploy models created with large social media training data sets.\\nEvaluating state-of-the-art statistical modeling and Machine Learning approaches.\\nDevelop unique approaches to complex modeling and inference problems which combine marketing and social media data knowledge with mathematical approaches to recognize patterns and trends in influencer marketing industries.\\nData Analysis, Visualization and Modeling with large text, image and video datasets\\nCreate data pipelines and demonstrate processes for Data Acquisition, Ingestion, Cleaning, and Transformation\\nWork closely with the CTO, Product, Engineering, DevOps and Ai Science teams\\nCollaborate with the product team, share feedback from project implementations and influence the product roadmap.\\nBe comfortable in a highly dynamic, agile environment without sacrificing the quality of work products.\\nStay current with emerging AI, MLOps, web and mobile technologies and trends.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For this task we have to scrap url for each job\n",
    "from selenium.common.exceptions import  NoSuchElementException\n",
    "url_job=[]\n",
    "for i in title:\n",
    "    url_job.append(i.get_attribute('href'))\n",
    "\n",
    "for k in url_job[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(k)\n",
    "        descript=driver.find_element_by_xpath(\"//div[@class='dang-inner-html']\").text\n",
    "        desc.append(descript)\n",
    "    except NoSuchElementException:\n",
    "        desc.append('NA')\n",
    "\n",
    "desc=desc[:10]\n",
    "desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791ec6e9",
   "metadata": {},
   "source": [
    ". Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3812be8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI Technologist Vacancy</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Roles and Responsibilities\\n\\n\\nDesired Candid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job Opening with Wipro For Data Scientist posi...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Chennai, Bang...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>Greetings from Wipro !\\n\\nWe are hiring for Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>As a Senior Data Scientist for Walmart, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Drive data-derived insights across the wide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru, D...</td>\n",
       "      <td>Genpact</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Immediate Joiners</td>\n",
       "      <td>Noida, Mumbai, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Bristlecone</td>\n",
       "      <td>An avid technology enthusiast , Machine leanin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist- AI/ML- R&amp;D</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>EXL</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Urgent Hiring For AI Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>Job Description\\nDevelop math models and algor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0                            AI Technologist Vacancy   \n",
       "1  Job Opening with Wipro For Data Scientist posi...   \n",
       "2                                     Data Scientist   \n",
       "3                              Senior Data Scientist   \n",
       "4                              Senior Data Scientist   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                 Data Scientist - Immediate Joiners   \n",
       "8                         Data Scientist- AI/ML- R&D   \n",
       "9                Urgent Hiring For AI Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "1  Kolkata, Hyderabad/Secunderabad, Chennai, Bang...   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Bangalore/Bengaluru, D...   \n",
       "7           Noida, Mumbai, Pune, Bangalore/Bengaluru   \n",
       "8  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "9  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "\n",
       "                              Company  \\\n",
       "0                               Wipro   \n",
       "1                               Wipro   \n",
       "2                             Genpact   \n",
       "3                             Walmart   \n",
       "4                             Walmart   \n",
       "5                             Genpact   \n",
       "6                             Genpact   \n",
       "7                         Bristlecone   \n",
       "8                                 EXL   \n",
       "9  Ashkom Media India Private Limited   \n",
       "\n",
       "                                     Job Description  \n",
       "0  Roles and Responsibilities\\n\\n\\nDesired Candid...  \n",
       "1  Greetings from Wipro !\\n\\nWe are hiring for Da...  \n",
       "2                                                 NA  \n",
       "3    As a Senior Data Scientist for Walmart, you ...  \n",
       "4    Drive data-derived insights across the wide ...  \n",
       "5                                                 NA  \n",
       "6                                                 NA  \n",
       "7  An avid technology enthusiast , Machine leanin...  \n",
       "8                                                 NA  \n",
       "9  Job Description\\nDevelop math models and algor...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Scientist={'Job':job,'Location':loc,\n",
    "              'Company':comp,'Job Description':desc}\n",
    "Data_Scientist=pd.DataFrame(data=Data_Scientist)\n",
    "Data_Scientist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232e9cc",
   "metadata": {},
   "source": [
    "# Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c79a777",
   "metadata": {},
   "source": [
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fccd1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ad2cb443",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da026e9",
   "metadata": {},
   "source": [
    ". Enter “Data Scientist” in “Skill,Designations,Companies” field "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5a5b2e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_designation = driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input')\n",
    "search_designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "009b39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('/html/body/div/div[2]/div[3]/div/div/div[6]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "797b1d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying filter for loaction 'Delhi/NCR'\n",
    "\n",
    "driver.find_element_by_xpath(\"//span[@class='ellipsis fleft']\").click()\n",
    "time.sleep(4)\n",
    "\n",
    "#Applying fliter for salary '3-6 lakhs'\n",
    "\n",
    "driver.find_element_by_xpath(\"//span[@title='3-6 Lakhs']\").click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19708ab",
   "metadata": {},
   "source": [
    ". Then scrape the data for the first 10 jobs results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b3b5a0b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hiring MBA Freshers -2022 - For our Talent Acq...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Bangalo...</td>\n",
       "      <td>KPMG</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aem Developer</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tcs Hiring For Site Reliability Engineer_ PAN ...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Greetings From Cognizant!!!!!!</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Cognizant Technology Solutions India Pvt Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tcs is Hiring For Angular Js Developer For PAN...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Talend Developer</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Capgemini</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Java Angular Developer</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Java Angular Developer</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tcs Hiring For RPA Automation Anywhere_PAN India</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Chennai...</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AWS DevOps Engineer</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Infosys</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Job  \\\n",
       "0  Hiring MBA Freshers -2022 - For our Talent Acq...   \n",
       "1                                      Aem Developer   \n",
       "2  Tcs Hiring For Site Reliability Engineer_ PAN ...   \n",
       "3                     Greetings From Cognizant!!!!!!   \n",
       "4  Tcs is Hiring For Angular Js Developer For PAN...   \n",
       "5                                   Talend Developer   \n",
       "6                             Java Angular Developer   \n",
       "7                             Java Angular Developer   \n",
       "8   Tcs Hiring For RPA Automation Anywhere_PAN India   \n",
       "9                                AWS DevOps Engineer   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Kolkata, Hyderabad/Secunderabad, Pune, Bangalo...   \n",
       "1  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "2  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "3  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "4  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "6                                 (WFH during Covid)   \n",
       "7  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "8  Kolkata, Hyderabad/Secunderabad, Pune, Chennai...   \n",
       "9  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "\n",
       "                                        Company Experience  \n",
       "0                                          KPMG    0-0 Yrs  \n",
       "1                                     Cognizant    3-8 Yrs  \n",
       "2               TATA CONSULTANCY SERVICES (TCS)   5-10 Yrs  \n",
       "3  Cognizant Technology Solutions India Pvt Ltd    2-7 Yrs  \n",
       "4                Tata Consultancy Services Ltd.    2-6 Yrs  \n",
       "5                                     Capgemini    6-9 Yrs  \n",
       "6               TATA CONSULTANCY SERVICES (TCS)    2-7 Yrs  \n",
       "7               TATA CONSULTANCY SERVICES (TCS)    2-5 Yrs  \n",
       "8               TATA CONSULTANCY SERVICES (TCS)    3-8 Yrs  \n",
       "9                                       Infosys   7-12 Yrs  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create empty list in which we will update the required data\n",
    "Job=[]\n",
    "Loc=[]\n",
    "Comp=[]\n",
    "Exp=[]\n",
    "\n",
    "#scrapping job titles\n",
    "titles = driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    Job.append(i.text)\n",
    "    Job=Job[:10]\n",
    "    \n",
    "#scrapping location\n",
    "loct=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "for i in loct:\n",
    "    Loc.append(i.text)\n",
    "    Loc=Loc[:10]\n",
    "    \n",
    "#scrapping company\n",
    "comp=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in comp:\n",
    "    Comp.append(i.text)\n",
    "    Comp=Comp[:10]\n",
    "    \n",
    "#scrapping experience\n",
    "expe=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span\")\n",
    "for i in expe:\n",
    "    Exp.append(i.text)\n",
    "    Exp=Exp[:10]\n",
    "\n",
    "#Creating the DataFrame\n",
    "Data_Scientist_Delhi={'Job':Job,'Location':Loc,\n",
    "              'Company':Comp,'Experience':Exp}\n",
    "Data_Scientist_Delhi=pd.DataFrame(data=Data_Scientist_Delhi)\n",
    "Data_Scientist_Delhi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f41a5c",
   "metadata": {},
   "source": [
    "\n",
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8217894d",
   "metadata": {},
   "source": [
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605f208",
   "metadata": {},
   "source": [
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then \n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8b72f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2aa6fc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "631b8b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"390ef729ac887f3446f7e3d00e217bc8\", element=\"9e04f626-e52b-4cd8-a1c5-639d55879c4a\")>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_locn = driver.find_element_by_xpath('/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_locn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6515e340",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_locn.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3eb50924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"390ef729ac887f3446f7e3d00e217bc8\", element=\"8cddda9d-0dff-4016-9a05-68fea05e0e3e\")>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## clicking search button using absolute xpath function\n",
    "search_btn = driver.find_element_by_xpath('/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec91567b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5ecdfe",
   "metadata": {},
   "source": [
    "Extracting brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b173a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['Mi', 'Fastrack', 'SRPM', 'Fastrack', 'Elligator', 'PIRASO', 'PIRASO', 'PIRASO', 'PIRASO', 'Fastrack', 'ROZZETTA CRAFT', 'New Specs', 'Fastrack', 'Mi', 'VINCENT CHASE', 'ROZZETTA CRAFT', 'SUNBEE', 'PIRASO', 'United Colors of Benetton', 'SHAAH COLLECTIONS', 'New Specs', 'Lee Topper', 'Elligator', 'SUNBEE', 'ROZZETTA CRAFT', 'SRPM', 'GANSTA', 'Fastrack', 'ROYAL SON', 'Urbanic', 'Lee Topper', 'PIRASO', 'GANSTA', 'WROGN', 'AISLIN', 'PIRASO', 'HRX by Hrithik Roshan', 'ROYAL SON', 'Fastrack', 'SHAAH COLLECTIONS']\n"
     ]
    }
   ],
   "source": [
    "brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "### now brand is inside the brand tag we will iterate over it to extract brands\n",
    "brand_sg = []\n",
    "for i in brand:\n",
    "    brand_sg.append(i.text)\n",
    "print(len(brand_sg))\n",
    "print(brand_sg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe25bb",
   "metadata": {},
   "source": [
    "product description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45bcb4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['₹649₹1,19945% off', 'UV Protection Rectangular Sunglasses (Free Size)', '₹199₹1,29984% off', 'UV Protection Wayfarer Sunglasses (Free Size)', '₹280₹2,49588% off', '₹199₹1,59987% off', '₹199₹1,59987% off', '₹319₹2,59987% off', '₹272₹2,59989% off', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', '₹449₹1,99977% off', 'UV Protection Rectangular Sunglasses (Free Size)', '₹899₹1,29930% off', '₹599₹99940% off', 'by Lenskart Polarized, UV Protection Cat-eye Sunglasses...', '₹314₹1,99984% off', 'UV Protection, Polarized Wayfarer Sunglasses (Free Size...', '₹219₹1,59986% off', '₹669₹3,70081% off', 'UV Protection, Polarized, Mirrored Rectangular Sunglass...', 'Mirrored, UV Protection, Riding Glasses, Others Round S...', 'Riding Glasses Wrap-around Sunglasses (Free Size)', '₹195₹99880% off', 'UV Protection, Polarized, Mirrored Retro Square Sunglas...', '₹449₹2,22579% off', '₹195₹99980% off', '₹207₹1,79988% off', 'UV Protection Aviator Sunglasses (Free Size)', '₹531₹1,99973% off', 'Others Oval Sunglasses (Free Size)', '₹259₹1,29980% off', '₹307₹1,59980% off', '₹279₹1,99986% off', 'Polarized Aviator Sunglasses (44)', '₹415₹1,52572% off', '₹307₹2,59988% off', '₹999₹2,59961% off', '₹359₹1,49976% off', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Round Sunglasses (Free Size)']\n"
     ]
    }
   ],
   "source": [
    "product = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]')\n",
    "\n",
    "product_sg = []\n",
    "for i in product:\n",
    "    product_sg.append(i.text.split(\"\\n\")[-3])\n",
    "print(len(product_sg))\n",
    "print(product_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34fc7f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "['₹649', '₹639', '₹199', '₹699', '₹280', '₹199', '₹199', '₹319', '₹272', '₹599', '₹449', '₹264', '₹899', '₹599', '₹719', '₹314', '₹283', '₹219', '₹669', '₹195', '₹299', '₹299', '₹195', '₹259', '₹449', '₹195', '₹207', '₹629', '₹531', '₹449', '₹259', '₹307', '₹279', '₹449', '₹415', '₹307', '₹999', '₹359', '₹849', '₹279']\n"
     ]
    }
   ],
   "source": [
    "price = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "\n",
    "price_sg = []\n",
    "for i in price:\n",
    "    price_sg.append(i.text)\n",
    "    price_sg = price_sg\n",
    "print(len(price_sg))\n",
    "print(price_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "37966691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"390ef729ac887f3446f7e3d00e217bc8\", element=\"291cff6e-3f2c-4d47-a9e6-c31543694dbd\")>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### clicking on next button \n",
    "next_btn = driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]/span')\n",
    "next_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c552019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b468b4d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "['Mi', 'Fastrack', 'SRPM', 'Fastrack', 'Elligator', 'PIRASO', 'PIRASO', 'PIRASO', 'PIRASO', 'Fastrack', 'ROZZETTA CRAFT', 'New Specs', 'Fastrack', 'Mi', 'VINCENT CHASE', 'ROZZETTA CRAFT', 'SUNBEE', 'PIRASO', 'United Colors of Benetton', 'SHAAH COLLECTIONS', 'New Specs', 'Lee Topper', 'Elligator', 'SUNBEE', 'ROZZETTA CRAFT', 'SRPM', 'GANSTA', 'Fastrack', 'ROYAL SON', 'Urbanic', 'Lee Topper', 'PIRASO', 'GANSTA', 'WROGN', 'AISLIN', 'PIRASO', 'HRX by Hrithik Roshan', 'ROYAL SON', 'Fastrack', 'SHAAH COLLECTIONS', 'PIRASO', 'Fastrack', 'Lee Topper', 'Singco India', 'United Colors of Benetton', 'kingsunglasses', 'PIRASO', 'LIZA ANGEL', 'ROYAL SON', 'Fastrack', 'VINCENT CHASE', 'Arnette', 'PHENOMENAL', 'Fastrack', 'SRPM', 'ROZZETTA CRAFT', 'AISLIN', 'ROZZETTA CRAFT', 'Fastrack', 'ROZZETTA CRAFT', 'SRPM', 'SUNBEE', 'kingsunglasses', 'GANSTA', 'New Specs', 'VINCENT CHASE', 'Ray-Ban', 'Arnette', 'AISLIN', 'NuVew', 'PHENOMENAL', 'ROYAL SON', 'PIRASO', 'ROZZETTA CRAFT', 'kingsunglasses', 'ROYAL SON', 'VINCENT CHASE', 'VINCENT CHASE', 'ROYAL SON', 'Arnette']\n"
     ]
    }
   ],
   "source": [
    "## Extracting brand name from 40-80\n",
    "brand = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand:\n",
    "    brand_sg.append(i.text)\n",
    "print(len(brand_sg))\n",
    "print(brand_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "81757f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "['₹649₹1,19945% off', 'UV Protection Rectangular Sunglasses (Free Size)', '₹199₹1,29984% off', 'UV Protection Wayfarer Sunglasses (Free Size)', '₹280₹2,49588% off', '₹199₹1,59987% off', '₹199₹1,59987% off', '₹319₹2,59987% off', '₹272₹2,59989% off', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', '₹449₹1,99977% off', 'UV Protection Rectangular Sunglasses (Free Size)', '₹899₹1,29930% off', '₹599₹99940% off', 'by Lenskart Polarized, UV Protection Cat-eye Sunglasses...', '₹314₹1,99984% off', 'UV Protection, Polarized Wayfarer Sunglasses (Free Size...', '₹219₹1,59986% off', '₹669₹3,70081% off', 'UV Protection, Polarized, Mirrored Rectangular Sunglass...', 'Mirrored, UV Protection, Riding Glasses, Others Round S...', 'Riding Glasses Wrap-around Sunglasses (Free Size)', '₹195₹99880% off', 'UV Protection, Polarized, Mirrored Retro Square Sunglas...', '₹449₹2,22579% off', '₹195₹99980% off', '₹207₹1,79988% off', 'UV Protection Aviator Sunglasses (Free Size)', '₹531₹1,99973% off', 'Others Oval Sunglasses (Free Size)', '₹259₹1,29980% off', '₹307₹1,59980% off', '₹279₹1,99986% off', 'Polarized Aviator Sunglasses (44)', '₹415₹1,52572% off', '₹307₹2,59988% off', '₹999₹2,59961% off', '₹359₹1,49976% off', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', 'UV Protection Round Sunglasses (Free Size)', ['PIRASO', 'UV Protection Aviator Sunglasses (54)', '₹198₹1,59987% off', 'Free delivery', 'EOSS Special'], ['Fastrack', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', '₹849₹99915% off', 'Free delivery'], ['Lee Topper', 'UV Protection Rectangular Sunglasses (Free Size)', '₹219₹99978% off', 'Free delivery'], ['Singco India', 'Gradient, Toughened Glass Lens, UV Protection Retro Squ...', '₹630₹2,99978% off', 'Free delivery', 'EOSS Special'], ['United Colors of Benetton', 'Mirrored, UV Protection Round Sunglasses (57)', '₹669₹3,70081% off', 'Free delivery', 'EOSS Special'], ['kingsunglasses', 'UV Protection, Mirrored Aviator Sunglasses (Free Size)', '₹269₹1,89985% off', 'Free delivery'], ['PIRASO', 'UV Protection Over-sized Sunglasses (65)', '₹410₹2,59984% off', 'Free delivery', 'EOSS Special'], ['LIZA ANGEL', 'Riding Glasses, Night Vision Spectacle Sunglasses (Fre...', '₹199₹99980% off', 'Size Free Size'], ['ROYAL SON', 'UV Protection, Gradient Butterfly Sunglasses (62)', '₹531₹1,99973% off', 'Free delivery'], ['Fastrack', 'UV Protection Wayfarer Sunglasses (Free Size)', '₹759₹89915% off', 'Free delivery'], ['VINCENT CHASE', 'by Lenskart Polarized, UV Protection Round Sunglasses (...', '₹719₹1,99964% off', 'Free delivery'], ['Arnette', 'Others Oval Sunglasses (53)', '₹2,359₹6,39063% off', 'Free delivery', 'EOSS Special'], ['PHENOMENAL', 'UV Protection, Mirrored Clubmaster Sunglasses (Free Siz...', '₹332₹1,99883% off', 'Free delivery'], ['Fastrack', 'Gradient, UV Protection Wayfarer Sunglasses (Free Size)', '₹699₹89922% off', 'Free delivery'], ['SRPM', 'Night Vision, UV Protection Round Sunglasses (54)', '₹207₹99979% off', 'Free delivery', 'EOSS Special'], ['ROZZETTA CRAFT', 'UV Protection, Gradient Retro Square Sunglasses (Free S...', '₹314₹1,99984% off', 'Free delivery', 'EOSS Special'], ['AISLIN', 'UV Protection, Gradient Retro Square Sunglasses (58)', '₹415₹1,52572% off', 'Free delivery'], ['ROZZETTA CRAFT', 'UV Protection, Gradient Rectangular Sunglasses (Free Si...', '₹359₹1,99982% off', 'Free delivery', 'EOSS Special'], ['Fastrack', 'UV Protection Aviator Sunglasses (58)', '₹1,025₹1,29921% off', 'Free delivery'], ['ROZZETTA CRAFT', 'UV Protection Spectacle Sunglasses (Free Size)', '₹359₹1,99982% off', 'Free delivery', 'EOSS Special'], ['SRPM', 'UV Protection Wayfarer Sunglasses (53)', '₹221₹99877% off', 'Free delivery', 'EOSS Special'], ['SUNBEE', 'UV Protection, Polarized, Mirrored Wayfarer Sunglasses ...', '₹283₹1,29978% off', 'Free delivery'], ['kingsunglasses', 'Mirrored, UV Protection Wayfarer Sunglasses (Free Size)', '₹269₹1,49982% off', 'Free delivery'], ['GANSTA', 'UV Protection Aviator Sunglasses (57)', '₹279₹1,99986% off', 'Free delivery', 'EOSS Special'], ['New Specs', 'UV Protection Rectangular Sunglasses (Free Size)', '₹189₹1,59988% off', 'Free delivery'], ['VINCENT CHASE', 'by Lenskart Polarized, UV Protection Aviator Sunglasses...', '₹683₹1,99965% off', 'Free delivery'], ['Ray-Ban', 'Mirrored Aviator Sunglasses (63)', '₹3,639₹5,49033% off', 'Free delivery', 'EOSS Special'], ['Arnette', 'Others Retro Square Sunglasses (55)', '₹2,919₹7,79062% off', 'Free delivery', 'EOSS Special'], ['AISLIN', 'UV Protection, Gradient Oval Sunglasses (58)', '₹415₹1,52572% off', 'Free delivery', 'EOSS Special'], ['NuVew', 'UV Protection Sports Sunglasses (62)', '₹307₹1,24575% off', 'Free delivery', 'EOSS Special'], ['PHENOMENAL', 'UV Protection Retro Square Sunglasses (Free Size)', '₹341₹1,99982% off', 'Free delivery'], ['ROYAL SON', 'Polarized, UV Protection Round Sunglasses (52)', '₹639₹1,99968% off', 'Free delivery'], ['PIRASO', 'UV Protection Butterfly Sunglasses (60)', '₹359₹2,59986% off', 'Free delivery', 'EOSS Special'], ['ROZZETTA CRAFT', 'UV Protection, Gradient Round Sunglasses (Free Size)', '₹359₹1,99982% off', 'Free delivery', 'EOSS Special'], ['kingsunglasses', 'UV Protection Rectangular Sunglasses (55)', '₹189₹1,29985% off', 'Free delivery'], ['ROYAL SON', 'UV Protection, Polarized Wayfarer Sunglasses (54)', '₹639₹1,99968% off', 'Free delivery', 'Lowest price since launch'], ['VINCENT CHASE', 'by Lenskart UV Protection Aviator Sunglasses (Free Size...', '₹720₹1,99963% off', 'Free delivery', 'Lowest price in the year'], ['VINCENT CHASE', 'by Lenskart UV Protection Wayfarer Sunglasses (51)', '₹711₹1,99964% off', 'Free delivery'], ['ROYAL SON', 'Mirrored Aviator Sunglasses (Free Size)', '₹359₹1,49976% off', 'Free delivery', 'EOSS Special'], ['Arnette', 'Others Rectangular Sunglasses (56)', '₹2,919₹7,79062% off', 'Free delivery', 'EOSS Special']]\n"
     ]
    }
   ],
   "source": [
    "product2 = driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]')\n",
    "for i in product2:\n",
    "    product_sg.append(i.text.split('\\n'))\n",
    "print(len(product_sg))\n",
    "print(product_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3b2f8019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "['₹649', '₹639', '₹199', '₹699', '₹280', '₹199', '₹199', '₹319', '₹272', '₹599', '₹449', '₹264', '₹899', '₹599', '₹719', '₹314', '₹283', '₹219', '₹669', '₹195', '₹299', '₹299', '₹195', '₹259', '₹449', '₹195', '₹207', '₹629', '₹531', '₹449', '₹259', '₹307', '₹279', '₹449', '₹415', '₹307', '₹999', '₹359', '₹849', '₹279', '₹198', '₹849', '₹219', '₹630', '₹669', '₹269', '₹410', '₹199', '₹531', '₹759', '₹719', '₹2,359', '₹332', '₹699', '₹207', '₹314', '₹415', '₹359', '₹1,025', '₹359', '₹221', '₹283', '₹269', '₹279', '₹189', '₹683', '₹3,639', '₹2,919', '₹415', '₹307', '₹341', '₹639', '₹359', '₹359', '₹189', '₹639', '₹720', '₹711', '₹359', '₹2,919']\n"
     ]
    }
   ],
   "source": [
    "price2 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in price2:\n",
    "    price_sg.append(i.text)\n",
    "    price_sg = price_sg\n",
    "print(len(price_sg))\n",
    "print(price_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55db9b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"390ef729ac887f3446f7e3d00e217bc8\", element=\"291cff6e-3f2c-4d47-a9e6-c31543694dbd\")>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### clicking on next button \n",
    "next_btn2 = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]/span')\n",
    "next_btn2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "229f5c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_btn2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "034e7564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "['Mi', 'Fastrack', 'SRPM', 'Fastrack', 'Elligator', 'PIRASO', 'PIRASO', 'PIRASO', 'PIRASO', 'Fastrack', 'ROZZETTA CRAFT', 'New Specs', 'Fastrack', 'Mi', 'VINCENT CHASE', 'ROZZETTA CRAFT', 'SUNBEE', 'PIRASO', 'United Colors of Benetton', 'SHAAH COLLECTIONS', 'New Specs', 'Lee Topper', 'Elligator', 'SUNBEE', 'ROZZETTA CRAFT', 'SRPM', 'GANSTA', 'Fastrack', 'ROYAL SON', 'Urbanic', 'Lee Topper', 'PIRASO', 'GANSTA', 'WROGN', 'AISLIN', 'PIRASO', 'HRX by Hrithik Roshan', 'ROYAL SON', 'Fastrack', 'SHAAH COLLECTIONS', 'PIRASO', 'Fastrack', 'Lee Topper', 'Singco India', 'United Colors of Benetton', 'kingsunglasses', 'PIRASO', 'LIZA ANGEL', 'ROYAL SON', 'Fastrack', 'VINCENT CHASE', 'Arnette', 'PHENOMENAL', 'Fastrack', 'SRPM', 'ROZZETTA CRAFT', 'AISLIN', 'ROZZETTA CRAFT', 'Fastrack', 'ROZZETTA CRAFT', 'SRPM', 'SUNBEE', 'kingsunglasses', 'GANSTA', 'New Specs', 'VINCENT CHASE', 'Ray-Ban', 'Arnette', 'AISLIN', 'NuVew', 'PHENOMENAL', 'ROYAL SON', 'PIRASO', 'ROZZETTA CRAFT', 'kingsunglasses', 'ROYAL SON', 'VINCENT CHASE', 'VINCENT CHASE', 'ROYAL SON', 'Arnette', 'PIRASO', 'ROZZETTA CRAFT', 'kingsunglasses', 'Fastrack', 'Fastrack', 'Fastrack', 'HRX by Hrithik Roshan', 'Urbanic', 'kingscape', 'PIRASO', 'New Specs', 'ROZZETTA CRAFT', 'CRYSTAL CART', 'New Specs', 'AISLIN', 'Lee Topper', 'Rich Club', 'Fastrack', 'maxa', 'AISLIN', 'Lee Topper', 'ROYAL SON', 'WROGN', 'Fastrack', 'Singco India', 'ROYAL SON', 'Fastrack', 'GHAWK', 'CRYSTAL CART', 'United Colors of Benetton', 'kingsunglasses', 'Fastrack', 'hipe', 'United Colors of Benetton', 'IDEE', 'AISLIN', 'Roadster', 'VINCENT CHASE', 'HRX by Hrithik Roshan', 'Fastrack']\n"
     ]
    }
   ],
   "source": [
    "## Extracting brand name from 80-100\n",
    "brand3 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in brand3:\n",
    "    brand_sg.append(i.text)\n",
    "print(len(brand_sg))\n",
    "print(brand_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9a4b63e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "brand_sg = brand_sg[:100]\n",
    "print(len(brand_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb7446ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "product3 = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "for i in product3:\n",
    "    product_sg.append(i.text.split('\\n'))\n",
    "product_sg = product_sg[:100]\n",
    "print(len(product_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d16844b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "price3 = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "for i in price3:\n",
    "    price_sg.append(i.text)\n",
    "price_sg = price_sg[:100]\n",
    "print(len(price_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "952301c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi</td>\n",
       "      <td>₹649₹1,19945% off</td>\n",
       "      <td>₹649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>₹199₹1,29984% off</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹280₹2,49588% off</td>\n",
       "      <td>₹280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lee Topper</td>\n",
       "      <td>[Lee Topper]</td>\n",
       "      <td>₹276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>[Rich Club]</td>\n",
       "      <td>₹199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>[Fastrack]</td>\n",
       "      <td>₹789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>maxa</td>\n",
       "      <td>[maxa]</td>\n",
       "      <td>₹189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>[AISLIN]</td>\n",
       "      <td>₹415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                               Product description Price\n",
       "0           Mi                                 ₹649₹1,19945% off  ₹649\n",
       "1     Fastrack  UV Protection Rectangular Sunglasses (Free Size)  ₹639\n",
       "2         SRPM                                 ₹199₹1,29984% off  ₹199\n",
       "3     Fastrack     UV Protection Wayfarer Sunglasses (Free Size)  ₹699\n",
       "4    Elligator                                 ₹280₹2,49588% off  ₹280\n",
       "..         ...                                               ...   ...\n",
       "95  Lee Topper                                      [Lee Topper]  ₹276\n",
       "96   Rich Club                                       [Rich Club]  ₹199\n",
       "97    Fastrack                                        [Fastrack]  ₹789\n",
       "98        maxa                                            [maxa]  ₹189\n",
       "99      AISLIN                                          [AISLIN]  ₹415\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sunglasses=pd.DataFrame()\n",
    "Sunglasses['Brand'] = brand_sg\n",
    "Sunglasses['Product description'] = product_sg\n",
    "Sunglasses['Price'] = price_sg\n",
    "Sunglasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98756f",
   "metadata": {},
   "source": [
    "# Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55fe83f",
   "metadata": {},
   "source": [
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d484736",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "55278a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e9a4dc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '', '5', '5', '5', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "Ratings=[]\n",
    "for i in range(0,10,1):\n",
    "    Rating_iphone = driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for j in Rating_iphone:\n",
    "        Ratings.append(j.text)\n",
    "print(len(Ratings))\n",
    "print(Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "203b8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "['Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '', 'Simply awesome', 'Best in the market!', 'Perfect product!', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "Reviews = []\n",
    "for i in range(0,10,1):\n",
    "    Review_iphone = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "    for j in Review_iphone:\n",
    "        Reviews.append(j.text)\n",
    "print(len(Reviews))\n",
    "print(Reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cc056504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], [''], ['Really satisfied with the Product I received... It’s totally genuine and the packaging was also really good so if ur planning to buy just go for it.'], ['Great iPhone very snappy experience as apple kind. Upgraded from iPhone 7.', 'Pros', '-Camera top class', '- Battery top performed', '-Chipset no need to say as apple kind', '-Security as you expect from apple', '- Display super bright industry leading colour', 'accuracy and super responsive', '-Build quality as expect from apple sturdy', 'premium durable beautiful stylish.', '-Os most stable os in smartphone industry', '', 'Cons', '-No 5G', '-Display is not based on OLED technology', '-Charger headphones and 1 apple stic...', 'READ MORE'], ['Amazing phone with great cameras and better battery which gives you the best performance. I just love the camera .'], [''], [''], [''], [''], [''], [''], ['']]\n"
     ]
    }
   ],
   "source": [
    "full_reviews = []\n",
    "for i in range(0,10,1):\n",
    "    full_review_iphone = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "    for j in full_review_iphone:\n",
    "        full_reviews.append(j.text.split('\\n'))\n",
    "print(len(full_reviews))\n",
    "print(full_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "831d251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone = pd.DataFrame()\n",
    "iphone['Ratings'] = Ratings\n",
    "iphone['Reviews'] = Reviews\n",
    "iphone['Full Review'] = full_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9ebfd34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>[Really satisfied with the Product I received....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>[Great iPhone very snappy experience as apple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>[Amazing phone with great cameras and better b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings              Reviews  \\\n",
       "0        5       Simply awesome   \n",
       "1        5  Best in the market!   \n",
       "2        5     Perfect product!   \n",
       "3                                 \n",
       "4                                 \n",
       "..     ...                  ...   \n",
       "95                                \n",
       "96                                \n",
       "97                                \n",
       "98                                \n",
       "99                                \n",
       "\n",
       "                                          Full Review  \n",
       "0   [Really satisfied with the Product I received....  \n",
       "1   [Great iPhone very snappy experience as apple ...  \n",
       "2   [Amazing phone with great cameras and better b...  \n",
       "3                                                  []  \n",
       "4                                                  []  \n",
       "..                                                ...  \n",
       "95                                                 []  \n",
       "96                                                 []  \n",
       "97                                                 []  \n",
       "98                                                 []  \n",
       "99                                                 []  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb1af5",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088ee773",
   "metadata": {},
   "source": [
    "# Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "317caa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d0ab4ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "52cc2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_product = driver.find_element_by_xpath(\"//input[@class='_3704LK']\")\n",
    "search_product.send_keys(\"Sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c92ee1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410adce",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e3bc1950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Brand Name---------------------- \n",
      "['BRUTON', 'TR', 'BIRDE', 'Robbie jones', 'BRUTON', 'URBANBOX', 'Labbin', 'Rzisbo', 'BRUTON', 'Layasa', 'BRUTON', 'Echor', 'Robbie jones', 'Kraasa', 'aadi', 'Echor', 'Robbie jones', 'Dicy', 'D-SNEAKERZ', 'luxury fashion', 'Robbie jones', 'bluemaker', 'ASTEROID', 'BRUTON', 'Robbie jones', 'CAMPUS', 'KWIK FIT', 'luxury fashion', 'HOTSTYLE', 'CLYMB', 'PUMA', 'Bacan', 'Robbie jones', 'Robbie jones', 'U.S. POLO ASSN.', 'BIRDE', 'corsac', 'U.S. POLO ASSN.', 'aadi', 'CAMPUS']\n",
      "--------------------------------------------\n",
      "---------------Product Description-----------\n",
      "['Modern Trendy Sneakers Shoes Sneakers For Men', 'Sneakers For Men', 'Stylish Comfortable Lightweight, Breathable Walking Sho...', 'Casual Sneakers Green Shoes For Men And Boys Sneakers F...', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Lightweight Pack Of 1 Trendy Sneakers Sneakers For Men', 'Sneakers For Men', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Latest New Model Designer Sneakers Fashionable Trendy &...', 'Sneakers For Men', 'Shark-41 Sneakers For Men', 'Sneakers For Men', \"Men's Casual sneaker shoes running shoes walking shoes ...\", 'Sneakers For Men', 'Sneakers For Men', \"Casual , Partywear Sneakers Shoes For Men's And Boys Wh...\", 'Luxury Fashionable casual shoes Sneakers For Men', 'Casual Sneakers Canvas Shoes For Men Sneakers For Men', 'casual for men Sneakers For Men', \"Luxury Branded Fashionable Men's Casual Walking Partywe...\", 'Combo Pack Of 4 Casual Shoes Loafer Shoes Sneakers For ...', 'Casual Sneakers White Shoes For Men Sneakers For Men', 'KING PRO Sneakers For Men', 'Kwik FIT casual sneaker shoes and partywear shoes Casua...', 'Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Puma Rebound LayUp SL Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men', 'Casual Sneakers Shoes For Men And Boys Sneakers For Men', 'PANAL Sneakers For Men', 'Stylish Comfortable Lightweight, Breathable Walking Sho...', 'STYLISH MENS BLACK SNEAKER Sneakers For Men', 'Sneakers For Men', 'Sneakers For Men']\n",
      "--------------------------------------------\n",
      "---------------Product Description-----------\n",
      "['₹449', '₹359', '₹299', '₹399', '₹283', '₹198', '₹474', '₹438', '₹149', '₹359', '₹269', '₹598', '₹399', '₹419', '₹319', '₹509', '₹399', '₹284', '₹284', '₹448', '₹399', '₹424', '₹474', '₹499', '₹379', '₹699', '₹397', '₹450', '₹245', '₹519', '₹1,841', '₹474', '₹379', '₹399', '₹1,295', '₹283', '₹499', '₹1,214', '₹299', '₹924']\n",
      "---------------------------------------------\n",
      "----------------Discount---------------------\n",
      "['65% off', '76% off', '70% off', '60% off', '78% off', '80% off', '52% off', '56% off', '75% off', '64% off', '79% off', '70% off', '60% off', '58% off', '68% off', '66% off', '60% off', '52% off', '56% off', '65% off', '60% off', '57% off', '76% off', '85% off', '62% off', '36% off', '80% off', '65% off', '75% off', '65% off', '63% off', '52% off', '62% off', '60% off', '56% off', '71% off', '66% off', '59% off', '70% off', '15% off']\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Making empty lists for Brand,Product Description,Price and discounts :-\n",
    "Brand1 =[]\n",
    "prod_desc1=[]\n",
    "price1 =[]\n",
    "disc1=[]\n",
    "\n",
    "## Scrapping  first 40 Brand Name on page1:-\n",
    "br1 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in br1:\n",
    "    Brand1.append(i.text)\n",
    "print(\"-------------Brand Name---------------------- \")    \n",
    "print(Brand1)    \n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping  first 40 Product Description on page1:-\n",
    "\n",
    "pd1 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in pd1:\n",
    "    prod_desc1.append(i.text)\n",
    "print(\"---------------Product Description-----------\")  \n",
    "print(prod_desc1)\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping first 40 Price on page1 :-\n",
    "\n",
    "pp1 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "for i in pp1:\n",
    "    price1.append(i.text)\n",
    "    \n",
    "print(\"---------------Product Description-----------\")  \n",
    "print(price1)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "## Scrapping first 40 Discount on page1:-\n",
    "\n",
    "dc1 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "for i in dc1:\n",
    "    disc1.append(i.text)\n",
    "print(\"----------------Discount---------------------\")  \n",
    "print(disc1)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a20ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "59628482",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/search?q=Sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "519f3f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Brand Name---------------------- \n",
      "['Layasa', \"LEVI'S\", 'LE GREEM', 'Echor', 'RapidBox', 'NAUTICA', 'PUMA', 'BRUTON', 'Echor', 'U.S. POLO ASSN.', 'Echor', 'TR', \"LEVI'S\", 'KNIGHT WALKERS', 'ASTEROID', 'Labbin', 'Chevit', 'BIRDE', 'KNIGHTWING', 'Echor', 'AMICO', 'asics', 'revord', 'luxury fashion', 'aadi', 'Numenzo', 'asics', 'BRUTON', \"LEVI'S\", 'Dizzler', 'PUMA', 'HOTSTYLE', 'SPARX', 'BRUTON', 'WHITE WALKERS', 'luxury fashion', 'SPARX', 'PUMA', 'U.S. POLO ASSN.', 'Bacan']\n",
      "--------------------------------------------\n",
      "---------------Product Description-----------\n",
      "['Sneakers For Men', \"Levi's Men's Henry Sneakers Sneakers For Men\", 'Comfortable & Ultra Light Weight Sneaker Sneakers For M...', 'Latest New Model Designer Sneakers Fashionable Trendy &...', 'Sneakers For Men', 'Blend Sneakers For Men', 'Modern Trendy Sneakers Shoes Sneakers For Men', \"Men's Sneakers Fashion Lightweight Running Shoes Tennis...\", 'Sneakers For Men', \"Men's Sneakers Fashion Lightweight Running Shoes Tennis...\", 'Sneakers For Men', \"Levi's Men's Lancer Sneakers Sneakers For Men\", 'SS1100 Sneakers For Men', \"Original Luxury Branded Fashionable Men's Casual Walkin...\", 'Sneakers For Men', '516 Trendy Star Perfect Sneakers For Men', 'Stylish Comfortable Lightweight, Breathable Casual Walk...', \"Men's Casual sneaker shoes running shoes walking shoes ...\", 'Sneakers For Men', 'GEL-MOYA LS Sneakers For Men', 'Luxury Fashionable casual shoes Sneakers For Men', 'Sneakers For Men', 'LYTECOURT Sneakers For Men', 'Combo Pack Of 4 Casual Shoes Loafer Shoes Sneakers For ...', \"Men's Lancer Sneakers Sneakers For Men\", 'Puma Smash Vulc Sneakers For Men', 'Sneakers For Men', 'Men White Sneakers Sneakers For Men', 'Combo Pack Of 2 Latest Stylish Casual Shoes for Men Lac...', 'Stylish & Trending Outdoor Walking Comfortable Sneakers...', 'Sneakers For Men', 'SM-734 Sneakers For Men', 'Pacer Laser Sneakers For Men', 'CLARKIN Sneakers For Men', 'Sneakers For Men']\n",
      "--------------------------------------------\n",
      "---------------Product Description-----------\n",
      "['₹399', '₹1,399', '₹424', '₹598', '₹665', '₹1,319', '₹1,511', '₹449', '₹458', '₹1,295', '₹458', '₹359', '₹1,599', '₹664', '₹474', '₹474', '₹279', '₹299', '₹664', '₹509', '₹466', '₹1,944', '₹145', '₹448', '₹319', '₹509', '₹1,839', '₹499', '₹1,599', '₹470', '₹2,089', '₹245', '₹756', '₹499', '₹599', '₹450', '₹714', '₹1,538', '₹1,295', '₹474']\n",
      "---------------------------------------------\n",
      "----------------Discount---------------------\n",
      "['60% off', '50% off', '57% off', '70% off', '33% off', '75% off', '49% off', '65% off', '54% off', '56% off', '54% off', '76% off', '50% off', '66% off', '52% off', '52% off', '65% off', '70% off', '63% off', '66% off', '53% off', '61% off', '70% off', '65% off', '68% off', '83% off', '59% off', '85% off', '50% off', '34% off', '45% off', '75% off', '15% off', '80% off', '50% off', '65% off', '15% off', '65% off', '56% off', '52% off']\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Making empty lists for Brand,Product Description,Price and discounts :-\n",
    "Brand2 =[]\n",
    "prod_desc2=[]\n",
    "price2 =[]\n",
    "disc2=[]\n",
    "\n",
    "## Scrapping  next 40 Brand Name on page2:-\n",
    "br2 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in br2:\n",
    "    Brand2.append(i.text)\n",
    "print(\"-------------Brand Name---------------------- \")    \n",
    "print(Brand2)    \n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping  next 40 Product Description on page2:-\n",
    "\n",
    "pd2 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in pd2:\n",
    "    prod_desc2.append(i.text)\n",
    "print(\"---------------Product Description-----------\")  \n",
    "print(prod_desc2)\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping next 40 Price on page2 :-\n",
    "\n",
    "pp2 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "for i in pp2:\n",
    "    price2.append(i.text)\n",
    "    \n",
    "print(\"---------------Product Description-----------\")  \n",
    "print(price2)\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "## Scrapping next 40 Discount on page2:-\n",
    "\n",
    "dc2 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "for i in dc2:\n",
    "    disc2.append(i.text)\n",
    "print(\"----------------Discount---------------------\")  \n",
    "print(disc2)\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "827700ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/search?q=Sneakers&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=on&as=off&page=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0e09db9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Brand Name---------------------- \n",
      "['Chevit', 'DUNKASTON', 'luxury fashion', 'BRUTON', 'SPARX', 'corsac', 'U.S. POLO ASSN.', 'Rzisbo', 'RapidBox', 'LE GREEM', 'BIRDE', 'Echor', 'BIRDE', 'ASIAN', 'WOODLAND', 'TR', 'Airland', 'Rising Wolf', 'Bretton', 'Echor']\n",
      "--------------------------------------------\n",
      "---------------Product Description-----------\n",
      "['494 Perfect Sports Shoes for Running Training Hikking &...', 'Sneakers For Men', 'Luxury Fashionable casual sneaker shoes Sneakers For Me...', 'Modern Trendy Sneakers Shoes Sneakers For Men', 'Sneakers For Men', 'STYLISH MENS BLACK TRENDY SNEAKER FOR MENS Sneakers For...', 'Sneakers For Men', 'Sneakers For Men', 'Comfortable & Ultra Light Weight Sneaker Sneakers For M...', 'Sports Running Shoes Sneakers For Men', 'Latest New Model Designer Sneakers Fashionable Trendy &...', 'Stylish Comfortable Lightweight, Breathable Walking Sho...', 'Skypy-31 Walking Shoes,Training Shoes,Sneakers,Loafers,...', 'Sneakers For Men', 'Sneakers For Men', 'shoe Sneakers For Men', 'Sneakers For Men', \"Men's Casual sneaker shoes running shoes walking shoes ...\", 'CLARKIN 2.0 Sneakers For Men', \"White Sneaker For Men's/Boy's Sneakers For Men\"]\n",
      "--------------------------------------------\n",
      "---------------Product Description-----------\n",
      "['₹254', '₹363', '₹449', '₹449', '₹658', '₹499', '₹1,214', '₹438', '₹617', '₹424', '₹299', '₹598', '₹356', '₹493', '₹1,234', '₹359', '₹207', '₹458', '₹240', '₹509']\n",
      "---------------------------------------------\n",
      "----------------Discount---------------------\n",
      "['74% off', '75% off', '65% off', '65% off', '15% off', '66% off', '59% off', '56% off', '38% off', '57% off', '40% off', '70% off', '64% off', '38% off', '50% off', '76% off', '58% off', '77% off', '75% off', '66% off']\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "### Making empty lists for Brand,Product Description,Price and discounts :-\n",
    "Brand3 =[]\n",
    "prod_desc3=[]\n",
    "price3 =[]\n",
    "disc3=[]\n",
    "\n",
    "## Scrapping  next 20 Brand Name on page3:-\n",
    "br3 = driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "for i in br3:\n",
    "    Brand3.append(i.text)\n",
    "print(\"-------------Brand Name---------------------- \")    \n",
    "print(Brand3[:20])    \n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping  next 20 Product Description on page2:-\n",
    "\n",
    "pd3 = driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "for i in pd3:\n",
    "    prod_desc3.append(i.text)\n",
    "print(\"---------------Product Description-----------\")  \n",
    "print(prod_desc3[:20])\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping next 20 Price on page2 :-\n",
    "\n",
    "pp3 = driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "for i in pp3:\n",
    "    price3.append(i.text)\n",
    "    \n",
    "print(\"---------------Product Description-----------\")  \n",
    "print(price3[:20])\n",
    "print(\"---------------------------------------------\")\n",
    "\n",
    "## Scrapping next 20 Discount on page2:-\n",
    "\n",
    "dc3 = driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']/span\")\n",
    "for i in dc3:\n",
    "    disc3.append(i.text)\n",
    "print(\"----------------Discount---------------------\")  \n",
    "print(disc3[:20])\n",
    "print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "75876c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹359</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Green Shoes For Men And Boys S...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹283</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>TR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹359</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Airland</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹207</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rising Wolf</td>\n",
       "      <td>Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...</td>\n",
       "      <td>₹458</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bretton</td>\n",
       "      <td>Levi's Men's Henry Sneakers Sneakers For Men</td>\n",
       "      <td>₹240</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Echor</td>\n",
       "      <td>ST Activate V2 Sneakers For Men</td>\n",
       "      <td>₹509</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Brand Name                                Product Description Price  \\\n",
       "0         BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men  ₹449   \n",
       "1             TR                                   Sneakers For Men  ₹359   \n",
       "2          BIRDE  Stylish Comfortable Lightweight, Breathable Wa...  ₹299   \n",
       "3   Robbie jones  Casual Sneakers Green Shoes For Men And Boys S...  ₹399   \n",
       "4         BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men  ₹283   \n",
       "..           ...                                                ...   ...   \n",
       "95            TR                                   Sneakers For Men  ₹359   \n",
       "96       Airland  Super Stylish & Trendy Combo Pack of 02 Pairs ...  ₹207   \n",
       "97   Rising Wolf  Combo Pack Of 4 Casual Shoes Loafer Shoes Snea...  ₹458   \n",
       "98       Bretton       Levi's Men's Henry Sneakers Sneakers For Men  ₹240   \n",
       "99         Echor                    ST Activate V2 Sneakers For Men  ₹509   \n",
       "\n",
       "   Discount  \n",
       "0   65% off  \n",
       "1   76% off  \n",
       "2   70% off  \n",
       "3   60% off  \n",
       "4   78% off  \n",
       "..      ...  \n",
       "95  76% off  \n",
       "96  58% off  \n",
       "97  77% off  \n",
       "98  75% off  \n",
       "99  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Finally making Dataframe for 100 Sneakers:-\n",
    "brand_100 = []\n",
    "desc_100 = []\n",
    "price_100 = []\n",
    "disc_100 = []\n",
    "\n",
    "## Adding to get 100 Sneaker's Brand Name from FlipCart: -\n",
    "\n",
    "brand_100 = Brand1 + Brand2 + Brand3[:20]\n",
    "print(len(brand_100))\n",
    "\n",
    "## Adding to get 100 Sneaker's Product Description from FlipCart: -\n",
    "\n",
    "desc_100 = prod_desc1 + prod_desc2 + prod_desc3[:27]\n",
    "# print(len(prod_desc1))\n",
    "# print(len(prod_desc2))\n",
    "# print(len(prod_desc3))\n",
    "\n",
    "### Since  length of product description on page1 is 35,on second page only 30 and again on page 3 ,it is 36,\n",
    "##so make it 100,I have taken 35 data.\n",
    "\n",
    "print(len(desc_100))\n",
    "\n",
    "## Adding to get 100 Sneaker's price  from FlipCart: -\n",
    "price_100 = price1 + price2 + price3[:20]\n",
    "print(len(price_100))\n",
    "\n",
    "## Adding to get 100 Sneaker's Discount data  from FlipCart: -\n",
    "disc_100 = disc1 + disc2 + disc3[:20]\n",
    "print(len(disc_100))\n",
    "\n",
    "#### Making DataFrame\n",
    "\n",
    "sneaker_df = pd.DataFrame({'Brand Name': brand_100,\n",
    "                           'Product Description':desc_100,\n",
    "                           'Price':price_100,\n",
    "                           'Discount':disc_100\n",
    "    \n",
    "                          })\n",
    "\n",
    "sneaker_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c36f6",
   "metadata": {},
   "source": [
    "# Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a7c7ed",
   "metadata": {},
   "source": [
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a8eb34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cf0c8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Taking driver to the specific url:-\n",
    "driver.get(\"https://www.myntra.com/shoes?f=Color%3ABlack_36454f&rf=Price%3A7195.0_14130.0_7195.0%20TO%2014130.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5d24e046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Brand---------------------------\n",
      "['Nike', 'Puma', 'UNDER ARMOUR', 'Nike', 'UNDER ARMOUR', 'Skechers', 'Nike', 'Puma', 'Puma', 'Puma', 'Puma', 'UNDER ARMOUR', 'ADIDAS', 'Skechers', 'Vans', 'Puma', 'Skechers', 'UNDER ARMOUR', 'ADIDAS', 'ADIDAS', 'UNDER ARMOUR', 'Geox', 'J.FONTINI', 'Columbia', 'Hush Puppies', 'Geox', 'ASICS', 'Puma', 'Geox', 'Geox', 'Geox', 'Geox', 'ADIDAS', 'Geox', 'Geox', 'Columbia', 'UNDER ARMOUR', 'ADIDAS', 'Geox', 'Geox', 'EVADICT By Decathlon', 'Geox', 'Saint G', 'Geox', 'Geox', 'Clarks', 'UNDER ARMOUR', 'Xtep', 'KIPRUN By Decathlon', 'Clarks']\n",
      "50\n",
      "--------------------------------------------------\n",
      "------------------Short Description------------------\n",
      "['Women Pegasus 39 Running Shoes', 'Men Running Shoes', 'Men UA Charged Breeze Training', 'Women React Escape Running', 'Men UA Charged Vantage 2 Run', 'Women Go Walk EU Walking Shoes', 'Women React MR 3 Running Shoes', 'Eternity Nitro Running Shoes', 'Men M Nitro Running Shoess', 'Electrify Nitro Running Shoes', 'Men Velocity Nitro 2 Running', 'Men Charged Breeze Running', 'Men Solar Glide 4 ST Running', 'Men Woven Design Sneakers', 'Men Colourblocked Sneakers', 'Men Velocity Nitro Running', 'Men Textured Sneakers', 'Women Charged Breeze Running', 'Women Sports Shoes', 'Women Supernova Running Shoes', 'W omen TriBase Reign 4 Running', 'Men Leather Driving Shoes', 'Men Leather Fashion', 'Men FACET OUTDRY Trekking Shoe', 'Men Solid Leather Formal Slip-Ons', 'Men Textured Leather Driving Shoes', 'Men Sports Shoes', 'Women Liberate NITRO Running', 'Men Textured Leather Driving Shoes', 'Men Textured Leather Driving Shoes', 'Men Textured Leather Driving Shoes', 'Men Textured Leather Slip-On Sneakers', 'Women Solar Glide 5 Running', 'Women Textured Leather Loafers', 'Men Perforations Sneakers', 'Women REDMOND V2 TrekkingShoe', 'Men HOVR Sonic SE Running Shoe', 'Women KarlieKlossX9000 Running', 'Men Leather Sneakers', 'Men Leather Sneakers', 'Men Running Shoes', 'Men Leather Sneakers', 'Leather Block Sandals', 'Men Leather Loafers', 'Men Leather Sneakers', 'Men Leather Slip-Ons', 'Women Hovr Sonic SE Run Shoes', 'Men Running Shoes', 'Men Running Shoes', 'Men Solid Leather Formal Loafers']\n",
      "50\n",
      "--------------------------------------------\n",
      "-----------Price-----------------\n",
      "['Rs. 10495', 'Rs. 9999', 'Rs. 8999', 'Rs. 8046Rs. 11495', '(30% OFF)', 'Rs. 7999', 'Rs. 7499', 'Rs. 10495', 'Rs. 12999', 'Rs. 12999', 'Rs. 9999', 'Rs. 10999', 'Rs. 8999', 'Rs. 10499Rs. 14999', '(30% OFF)', 'Rs. 7499', 'Rs. 8249Rs. 10999', '(25% OFF)', 'Rs. 7199Rs. 11999', '( 40 % OFF)', 'Rs. 7999', 'Rs. 8999', 'Rs. 9899Rs. 17999', '(45% OFF)', 'Rs. 9999', 'Rs. 11999', 'Rs. 8393Rs. 11990', '(30% OFF)', 'Rs. 8490', 'Rs. 12999', 'Rs. 7999Rs. 9999', '(20% OFF)', 'Rs. 7343Rs. 10490', '(30% OFF)', 'Rs. 13999', 'Rs. 9999', 'Rs. 7693Rs. 10990', '(30% OFF)', 'Rs. 9891Rs. 10990', '(10% OFF)', 'Rs. 7693Rs. 10990', '(30% OFF)', 'Rs. 8991Rs. 9990', '(10% OFF)', 'Rs. 13999', 'Rs. 7492Rs. 9990', '(25% OFF)', 'Rs. 12591Rs. 13990', '(10% OFF)', 'Rs. 7999', 'Rs. 8999Rs. 9999', '(10% OFF)', 'Rs. 13999', 'Rs. 9891Rs. 10990', '(10% OFF)', 'Rs. 11691Rs. 12990', '(10% OFF)', 'Rs. 9239Rs. 10499', '(12% OFF)', 'Rs. 12591Rs. 13990', '(10% OFF)', 'Rs. 9810Rs. 10900', '(10% OFF)', 'Rs. 9093Rs. 12990', '(30% OFF)', 'Rs. 11691Rs. 12990', '(10% OFF)', 'Rs. 9999', 'Rs. 8999Rs. 9999', '(10% OFF)', 'Rs. 7699', 'Rs. 7372Rs. 10099', '(27% OFF)', 'Rs. 7999']\n",
      "74\n",
      "---------------------------------\n",
      "Rs. 10495\n",
      "Rs. 9999\n",
      "Rs. 8999\n",
      "Rs. 8046Rs. 11495\n",
      "(30% OFF)\n",
      "Rs. 7999\n",
      "Rs. 7499\n",
      "Rs. 10495\n",
      "Rs. 12999\n",
      "Rs. 12999\n",
      "Rs. 9999\n",
      "Rs. 10999\n",
      "Rs. 8999\n",
      "Rs. 10499Rs. 14999\n",
      "(30% OFF)\n",
      "Rs. 7499\n",
      "Rs. 8249Rs. 10999\n",
      "(25% OFF)\n",
      "Rs. 7199Rs. 11999\n",
      "( 40 % OFF)\n",
      "Rs. 7999\n",
      "Rs. 8999\n",
      "Rs. 9899Rs. 17999\n",
      "(45% OFF)\n",
      "Rs. 9999\n",
      "Rs. 11999\n",
      "Rs. 8393Rs. 11990\n",
      "(30% OFF)\n",
      "Rs. 8490\n",
      "Rs. 12999\n",
      "Rs. 7999Rs. 9999\n",
      "(20% OFF)\n",
      "Rs. 7343Rs. 10490\n",
      "(30% OFF)\n",
      "Rs. 13999\n",
      "Rs. 9999\n",
      "Rs. 7693Rs. 10990\n",
      "(30% OFF)\n",
      "Rs. 9891Rs. 10990\n",
      "(10% OFF)\n",
      "Rs. 7693Rs. 10990\n",
      "(30% OFF)\n",
      "Rs. 8991Rs. 9990\n",
      "(10% OFF)\n",
      "Rs. 13999\n",
      "Rs. 7492Rs. 9990\n",
      "(25% OFF)\n",
      "Rs. 12591Rs. 13990\n",
      "(10% OFF)\n",
      "Rs. 7999\n",
      "Rs. 8999Rs. 9999\n",
      "(10% OFF)\n",
      "Rs. 13999\n",
      "Rs. 9891Rs. 10990\n",
      "(10% OFF)\n",
      "Rs. 11691Rs. 12990\n",
      "(10% OFF)\n",
      "Rs. 9239Rs. 10499\n",
      "(12% OFF)\n",
      "Rs. 12591Rs. 13990\n",
      "(10% OFF)\n",
      "Rs. 9810Rs. 10900\n",
      "(10% OFF)\n",
      "Rs. 9093Rs. 12990\n",
      "(30% OFF)\n",
      "Rs. 11691Rs. 12990\n",
      "(10% OFF)\n",
      "Rs. 9999\n",
      "Rs. 8999Rs. 9999\n",
      "(10% OFF)\n",
      "Rs. 7699\n",
      "Rs. 7372Rs. 10099\n",
      "(27% OFF)\n",
      "Rs. 7999\n"
     ]
    }
   ],
   "source": [
    "## Creating empty lists for Brand,Short Description,and Price.:-\n",
    "brand1 = []\n",
    "Short_desc1=[]\n",
    "price1=[]\n",
    "\n",
    "## Scrapping Brand on page 1:- \n",
    "br1 = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "for i in br1:\n",
    "    brand1.append(i.text)\n",
    "print(\"-------------Brand---------------------------\")    \n",
    "print(brand1) \n",
    "print(len(brand1))\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "## Scrapping Short Description on page 1:- \n",
    "\n",
    "sd1 = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "for i in sd1:\n",
    "    Short_desc1.append(i.text)\n",
    "    \n",
    "print(\"------------------Short Description------------------\")\n",
    "print(Short_desc1)\n",
    "print(len(Short_desc1))\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping Price Data on page1 :-\n",
    "\n",
    "pp1 = driver.find_elements_by_xpath(\"//div[@class='product-price']/span\")\n",
    "for i in pp1:\n",
    "    price1.append(i.text)\n",
    "print(\"-----------Price-----------------\")  \n",
    "print(price1)\n",
    "print(len(price1))\n",
    "print(\"---------------------------------\")\n",
    "\n",
    "for i in price1:\n",
    "    print(i[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1a4a04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes?f=Color%3ABlack_36454f&p=2&rf=Price%3A7195.0_14130.0_7195.0%20TO%2014130.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "654212c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Brand---------------------------\n",
      "['Clarks', 'ASICS', 'J.FONTINI', 'ASICS', 'Bugatti', 'Clarks', 'DAVINCHI', 'Geox', 'Saint G', 'Heel & Buckle London', 'Clarks', 'Bugatti', 'Saint G', 'Saint G', 'Saint G', 'Louis Philippe', 'Kenkoh', 'Quechua By Decathlon', 'DAVINCHI', 'Geox', 'Geox', 'Geox', 'FILA', 'fitflop', 'Geox', 'Saint G', 'ECCO', 'Columbia', 'J.FONTINI', 'Geox', 'FILA', 'ECCO', 'Columbia', 'ECCO', 'ECCO', 'Cole Haan', 'Geox', 'J.FONTINI', 'Clarks', 'J.FONTINI', 'Heel & Buckle London', 'Geox', 'Geox', 'Geox', 'Geox', 'Geox', 'J.FONTINI', 'J.FONTINI', 'Saint G', 'PERFLY By Decathlon']\n",
      "50\n",
      "--------------------------------------------------\n",
      "------------------Short Description------------------\n",
      "['Men Solid Leather Formal Loafers', 'Women Running Shoes', 'Men Textured Leather Loafers', 'Women Running Shoes', 'Men Solid Leather Formal Derbys', 'Men Leather Derbys', 'Men Textured Formal Leather Loafers', 'Women Ballerinas Flats', 'Leather Rhinestone Decor Boots', 'Men Textured Leather Formal Loafers', 'Men Leather Slip-On Sneakers', 'Men Leather Monks', 'Stiletto Heel Mules', 'Suede Leather Block Heel Boots', 'Men Leather Chelsea Boots', 'Men Solid Leather Formal Loafers', 'Leather Flatform Sandals', 'Men Trekking Shoes', 'Men Formal Leather Slip-Ons', 'Leather Block Pumps', 'Women Ballerinas Flats', 'Textured Leather Block Pumps', 'Women Colourblocked Leather Sneakers', 'Embellished Leather Flatform Sandals', 'Flatform Heels', 'Suede Embellished Ankle Boots', 'Women Textured Leather Sneakers', 'PEAKFREAK OUTDRY Trekking Shoe', 'Men Leather Formal Loafers', 'Women Leather Slip-On Sneakers', 'Women Leather Sneakers', 'Leather Block Pumps', 'Women Trekking Shoes', 'Women Bella Leather Sneakers', 'Women Ballerinas Flats', 'Men GENERATION ZEROGRAND STITCHLITE', 'Men Solid Slip-On Sneakers', 'Men Textured Leather Loafers', 'Men Solid Formal Leather Derbys', 'Men Solid Loafers', 'Men Formal Leather Derby', 'Women Solid Leather Pumps', 'Men Leather Formal Slip-Ons', 'Women Leather Solid Pumps', 'Men Printed Slip-On Sneakers', 'Men Leather Sneakers', 'Men Black Leather Loafers', 'Men Leather Formal Loafers', 'Women Leather Heeled Mules', 'Men Textile Badminton Shoes']\n",
      "50\n",
      "--------------------------------------------\n",
      "-----------Price-----------------\n",
      "['Rs. 7999', 'Rs. 7599Rs. 7999', '(5% OFF)', 'Rs. 8490', 'Rs. 7999', 'Rs. 7999Rs. 9999', '(20% OFF)', 'Rs. 7499', 'Rs. 8990', 'Rs. 8055Rs. 8950', '(10% OFF)', 'Rs. 13205Rs. 13900', '(5% OFF)', 'Rs. 13990', 'Rs. 8999', 'Rs. 8999', 'Rs. 8075Rs. 8500', '(5% OFF)', 'Rs. 10355Rs. 10900', '(5% OFF)', 'Rs. 10710Rs. 11900', '(10% OFF)', 'Rs. 9999', 'Rs. 10400', 'Rs. 9999', 'Rs. 8990', 'Rs. 8992Rs. 11990', '(25% OFF)', 'Rs. 9891Rs. 10990', '(10% OFF)', 'Rs. 8992Rs. 11990', '(25% OFF)', 'Rs. 9999', 'Rs. 8299', 'Rs. 10791Rs. 11990', '(10% OFF)', 'Rs. 8455Rs. 8900', '(5% OFF)', 'Rs. 13999', 'Rs. 9999', 'Rs. 7490', 'Rs. 8242Rs. 10990', '(25% OFF)', 'Rs. 7999', 'Rs. 9999', 'Rs. 8999', 'Rs. 8999', 'Rs. 8999', 'Rs. 11999', 'Rs. 12591Rs. 13990', '(10% OFF)', 'Rs. 7990', 'Rs. 9999', 'Rs. 8990', 'Rs. 7990', 'Rs. 8242Rs. 10990', '(25% OFF)', 'Rs. 8991Rs. 9990', '(10% OFF)', 'Rs. 11990', 'Rs. 9793Rs. 13990', '(30% OFF)', 'Rs. 7699Rs. 10999', '(30% OFF)', 'Rs. 8490', 'Rs. 7490', 'Rs. 8900', 'Rs. 9211Rs. 9799', '(6% OFF)']\n",
      "69\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "## Creating empty lists for Brand,Short Description,and Price.:-\n",
    "brand2 = []\n",
    "Short_desc2=[]\n",
    "price2=[]\n",
    "\n",
    "## Scrapping Brand on page 2:- \n",
    "br2 = driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "for i in br2:\n",
    "    brand2.append(i.text)\n",
    "print(\"-------------Brand---------------------------\")    \n",
    "print(brand2) \n",
    "print(len(brand2))\n",
    "print(\"--------------------------------------------------\")\n",
    "\n",
    "## Scrapping Short Description on page 2:- \n",
    "\n",
    "sd2 = driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "for i in sd2:\n",
    "    Short_desc2.append(i.text)\n",
    "    \n",
    "print(\"------------------Short Description------------------\")\n",
    "print(Short_desc2)\n",
    "print(len(Short_desc2))\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "## Scrapping Price Data on page2 :-\n",
    "\n",
    "pp2= driver.find_elements_by_xpath(\"//div[@class='product-price']/span\")\n",
    "for i in pp2:\n",
    "    price2.append(i.text)\n",
    "print(\"-----------Price-----------------\")  \n",
    "print(price2)\n",
    "print(len(price2))\n",
    "print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f1af818e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>price_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women Pegasus 39 Running Shoes</td>\n",
       "      <td>Rs. 10495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men UA Charged Breeze Training</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Women React Escape Running</td>\n",
       "      <td>Rs. 8046Rs. 11495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men UA Charged Vantage 2 Run</td>\n",
       "      <td>(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Black Leather Loafers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Leather Formal Loafers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Mules</td>\n",
       "      <td>Rs. 11999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PERFLY By Decathlon</td>\n",
       "      <td>Men Textile Badminton Shoes</td>\n",
       "      <td>Rs. 12591Rs. 13990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand               Short Description           price_100\n",
       "0                  Nike  Women Pegasus 39 Running Shoes           Rs. 10495\n",
       "1                  Puma               Men Running Shoes            Rs. 9999\n",
       "2          UNDER ARMOUR  Men UA Charged Breeze Training            Rs. 8999\n",
       "3                  Nike      Women React Escape Running   Rs. 8046Rs. 11495\n",
       "4          UNDER ARMOUR    Men UA Charged Vantage 2 Run           (30% OFF)\n",
       "..                  ...                             ...                 ...\n",
       "95                 Geox            Men Leather Sneakers            Rs. 8999\n",
       "96            J.FONTINI       Men Black Leather Loafers            Rs. 8999\n",
       "97            J.FONTINI      Men Leather Formal Loafers            Rs. 8999\n",
       "98              Saint G      Women Leather Heeled Mules           Rs. 11999\n",
       "99  PERFLY By Decathlon     Men Textile Badminton Shoes  Rs. 12591Rs. 13990\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Making DataFrame for Shoes data  using colour and price filter from Myntra:-\n",
    "\n",
    "Brand_100 =[]\n",
    "short_desc_100=[]\n",
    "price_100 =[]\n",
    "\n",
    "## Adding to get 100 shoes's Brand from Myntra:-\n",
    "\n",
    "Brand_100 = brand1 + brand2\n",
    "print(len(Brand_100))\n",
    "\n",
    "## Adding to get 100 shoes's Short description from Myntra:- \n",
    "\n",
    "short_desc_100 = Short_desc1 + Short_desc2\n",
    "print(len(short_desc_100))\n",
    "\n",
    "## Adding to get 100 shoes's price from Myntra:- \n",
    "\n",
    "## Since on page1 price returns 68 list length and on page2 price returns 61 list lengthdata,so making it 50 used slicing \n",
    "\n",
    "price_100 = price1[:50] + price2[:50]\n",
    "print(len(price_100))\n",
    "shoes_df = pd.DataFrame({ 'Brand': Brand_100,\n",
    "                         'Short Description': short_desc_100,\n",
    "                         'price_100' : price_100\n",
    "    \n",
    "                        })\n",
    "\n",
    "shoes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c4231c",
   "metadata": {},
   "source": [
    "# Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c07131",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "43dc946a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "39b9e200",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9316cca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Xpath for Search:-\n",
    "search_prd = driver.find_element_by_xpath(\"//input[@class='nav-input nav-progressive-attribute']\")\n",
    "search_prd.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "599f4cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## xpath for clicking search:-\n",
    "search_click = driver.find_element_by_xpath(\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "97314f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/s?k=Laptop&i=computers&rh=n%3A1375424031&dc&crid=2L7IY8FBACAF&qid=1655471009&rnid=12598141031&sprefix=laptop%2Caps%2C1865&ref=sr_nr_p_n_feature_thirteen_browse-bin_13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "81ccd3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HP Pavilion 14 12th Gen Intel Core i5 16GB SDRAM/512GB SSD 14 inch(35.6cm) FHD,IPS,Micro-Edge Display/Intel UHD Graphics/B&O/Win 11/Alexa Built-in/Backlit KB/FPR/MSO 2021/Natural Silver, 14-dv2014TU', 'LG Gram 16 Intel Evo 11th Gen i7 Thin & Light Laptop 2K+ IPS 16:10 Display [16 GB RAM/ 512 GB SSD/ Windows 11 / Iris Xe Graphics/ Thunderbolt 4, USC -C x 2 / 1.19 kg, Black/ 3Yr Warranty] 16Z90P', 'ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) HD, Dual Core Intel Celeron N4020, Thin and Light Laptop (4GB RAM/256GB SSD/Integrated Graphics/Windows 11 Home/Transparent Silver/1.8 Kg), X515MA-BR011W', \"Lenovo IdeaPad 1 Intel Celeron N4020 11.6'' HD Laptop (4GB/256GB SSD/Windows 11/Office 2021/Platinum Grey/1.2Kg), 81VT009UIN\", 'Dell New Inspiron 3525 Laptop, AMD Athlon Silver 3050U, Win11 + Office\\'21, 8GB GDDR4, 256GB SSD, Radeon Graphics, 15.6\" (39.62Cms) HD Anti Glare (D560766WIN9BE, 1.68Kgs)', 'LG Gram 16 Intel Evo 11th Gen i7 Thin & Light Laptop 2K+ IPS 16:10 Display [16 GB RAM/ 512 GB SSD/ Windows 11 / Iris Xe Graphics/ Thunderbolt 4, USC -C x 2 / 1.19 kg, Black/ 3Yr Warranty] 16Z90P', 'Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" HD IPS Detachable 2-in-1 Laptop (4GB/128GB eMMC/Windows 10/1 Yr Warranty/Mineral Grey/1.1Kg), 82H0001YIN', 'Dell New Inspiron 3521 Laptop, Intel PQC-N5030, Win11 + Office\\'21, 8GB GDDR4, 256GB SSD, 15.6\" (39.62Cms) HD AG (D560756WIN9BE, 1.61Kgs)', 'Acer Aspire 3 AMD 3020e Dual core Processor 14 inches (35.5 cm) HD Display Laptop (4GB DDR4 RAM / 1TB HDD / Windows 11 Home/ Black /Narrow Bezel / 1.9 Kg, A314-22)', 'HP 247 G8 Laptop (Athlon P-3045B HD/ 14\" HD (35.56 cms) /8GB RAM DDR4 /1TB HDD / W11 SL)One Year Warranty, Black, 67U77PA)']\n",
      "10\n",
      "['4.4 out of 5 stars', '4.3 out of 5 stars', '4.1 out of 5 stars', '4.0 out of 5 stars', '4.0 out of 5 stars', '3.7 out of 5 stars', '4.1 out of 5 stars', '3.8 out of 5 stars', '3.6 out of 5 stars', '4.4 out of 5 stars']\n",
      "['68,990', '86,990', '26,990', '23,890', '29,990', '86,990', '21,990', '32,490', '24,990', '28,899']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion 14 12th Gen Intel Core i5 16GB SDR...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>68,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Gram 16 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>26,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad 1 Intel Celeron N4020 11.6'' HD...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>23,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell New Inspiron 3525 Laptop, AMD Athlon Silv...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG Gram 16 Intel Evo 11th Gen i7 Thin &amp; Light ...</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>21,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell New Inspiron 3521 Laptop, Intel PQC-N5030...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>32,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acer Aspire 3 AMD 3020e Dual core Processor 14...</td>\n",
       "      <td>3.6 out of 5 stars</td>\n",
       "      <td>24,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HP 247 G8 Laptop (Athlon P-3045B HD/ 14\" HD (3...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>28,899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  HP Pavilion 14 12th Gen Intel Core i5 16GB SDR...  4.4 out of 5 stars   \n",
       "1  LG Gram 16 Intel Evo 11th Gen i7 Thin & Light ...  4.3 out of 5 stars   \n",
       "2  ASUS VivoBook 15 (2021), 15.6-inch (39.62 cm) ...  4.1 out of 5 stars   \n",
       "3  Lenovo IdeaPad 1 Intel Celeron N4020 11.6'' HD...  4.0 out of 5 stars   \n",
       "4  Dell New Inspiron 3525 Laptop, AMD Athlon Silv...  4.0 out of 5 stars   \n",
       "5  LG Gram 16 Intel Evo 11th Gen i7 Thin & Light ...  3.7 out of 5 stars   \n",
       "6  Lenovo IdeaPad D330 Intel Celeron N4020 10.1\" ...  4.1 out of 5 stars   \n",
       "7  Dell New Inspiron 3521 Laptop, Intel PQC-N5030...  3.8 out of 5 stars   \n",
       "8  Acer Aspire 3 AMD 3020e Dual core Processor 14...  3.6 out of 5 stars   \n",
       "9  HP 247 G8 Laptop (Athlon P-3045B HD/ 14\" HD (3...  4.4 out of 5 stars   \n",
       "\n",
       "    Price  \n",
       "0  68,990  \n",
       "1  86,990  \n",
       "2  26,990  \n",
       "3  23,890  \n",
       "4  29,990  \n",
       "5  86,990  \n",
       "6  21,990  \n",
       "7  32,490  \n",
       "8  24,990  \n",
       "9  28,899  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Making empty lists for Title,ratings and Price :-\n",
    "title =[]\n",
    "ratings =[]\n",
    "price =[]\n",
    "\n",
    "#### Scrapping title data for laptop cpu type i7:-\n",
    "title_tags = driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in title_tags:\n",
    "    title.append(i.text)\n",
    "print(title[:10]) \n",
    "print(len(title[:10]))\n",
    "\n",
    "### Scrapping ratings data for Laptop cpu type i7:-\n",
    "rat_link = driver.find_elements_by_xpath(\"//div[@class='a-section a-spacing-none a-spacing-top-micro']//div[@class='a-row a-size-small']/span\")\n",
    " \n",
    "#print(rat.get_attribute('aria-label'))\n",
    "# for i in rat:\n",
    "#     ratings.append(i.get_attribute('aria-label'))\n",
    "# print(ratings)\n",
    "for rating in rat_link:\n",
    "    ratings.append(rating.get_attribute('aria-label'))\n",
    "print(ratings[0:20:2])    \n",
    "\n",
    "\n",
    "pp = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in pp:\n",
    "    price.append(i.text)\n",
    "print(price[:10])    \n",
    "\n",
    "#### Making dataframe:-\n",
    "laptop_df = pd.DataFrame({'Title':title[:10],\n",
    "                          'Rating':ratings[0:20:2],\n",
    "                          'Price':price[:10]\n",
    "    \n",
    "                         })\n",
    "laptop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a8d5fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606422da",
   "metadata": {},
   "source": [
    "# Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida \n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. \n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b45bbf",
   "metadata": {},
   "source": [
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4893aadf",
   "metadata": {},
   "source": [
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1153d1",
   "metadata": {},
   "source": [
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c86f70ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "52cbd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "4e46d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_option = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[6]')\n",
    "job_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "039f1ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scientist = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input')\n",
    "data_scientist.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "53933a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "280c6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "Search_location = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]')\n",
    "Search_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "364222d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/input')\n",
    "location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d3f0dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noida = driver.find_element_by_xpath('/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button')\n",
    "noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b9e6d3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['GENPACT India Private Limited', 'GENPACT India Private Limited', 'Hcl Technologies Limited', 'EXL Services.com ( I ) Pvt. Ltd.', 'Om Software Internet Solutions Private Limited', 'MOTHERSONSUMI INFOTECH & DESIGNS LIMITED', 'Ashkom Media India Private Limited', 'Ashkom Media India Private Limited', 'Ashkom Media India Private Limited', 'Zyoin']\n"
     ]
    }
   ],
   "source": [
    "company_name = []\n",
    "company_tag = driver.find_elements_by_xpath('//p[@class=\"company body-medium\"]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text)\n",
    "company_name = company_name[:10]\n",
    "print(len(company_name))\n",
    "print(company_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7d524e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['4.0', '4.0', '3.9', '3.9', '4.5', '3.3', '3.5', '3.5', '3.5', '3.9']\n"
     ]
    }
   ],
   "source": [
    "Ratings = []\n",
    "rating = driver.find_elements_by_xpath('//span[@class=\"body-small\"]')\n",
    "for i in rating:\n",
    "    Ratings.append(i.text)\n",
    "print(len(Ratings))\n",
    "print(Ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f32b134f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['8d ago', '15d ago', '18d ago', '28d ago', '19d ago', '16d ago', '15d ago', '15d ago', '15d ago', '1mon ago']\n"
     ]
    }
   ],
   "source": [
    "Posted_days = []\n",
    "day = driver.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "for i in day:\n",
    "    Posted_days.append(i.text)\n",
    "Posted_days = Posted_days[::2]\n",
    "print(len(Posted_days))\n",
    "print(Posted_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "329c1ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Posted-Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hcl Technologies Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>18d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EXL Services.com ( I ) Pvt. Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>28d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Om Software Internet Solutions Private Limited</td>\n",
       "      <td>4.5</td>\n",
       "      <td>19d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>3.3</td>\n",
       "      <td>16d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3.5</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zyoin</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1mon ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company Ratings Posted-Days\n",
       "0                   GENPACT India Private Limited     4.0      8d ago\n",
       "1                   GENPACT India Private Limited     4.0     15d ago\n",
       "2                        Hcl Technologies Limited     3.9     18d ago\n",
       "3                EXL Services.com ( I ) Pvt. Ltd.     3.9     28d ago\n",
       "4  Om Software Internet Solutions Private Limited     4.5     19d ago\n",
       "5        MOTHERSONSUMI INFOTECH & DESIGNS LIMITED     3.3     16d ago\n",
       "6              Ashkom Media India Private Limited     3.5     15d ago\n",
       "7              Ashkom Media India Private Limited     3.5     15d ago\n",
       "8              Ashkom Media India Private Limited     3.5     15d ago\n",
       "9                                           Zyoin     3.9    1mon ago"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = pd.DataFrame()\n",
    "jobs['Company'] = company_name\n",
    "jobs['Ratings'] = Ratings\n",
    "jobs['Posted-Days'] = Posted_days\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1bfbcf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4520db",
   "metadata": {},
   "source": [
    "# Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec9c39e",
   "metadata": {},
   "source": [
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464e68a0",
   "metadata": {},
   "source": [
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6bbc05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "226e1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4a7064f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_option = driver.find_element_by_xpath('/html/body/div[1]/nav/nav/a[4]')\n",
    "salary_option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "30b51c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### writting data scientist\n",
    "data_scientist = driver.find_element_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "data_scientist.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "172e45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_ds = driver.find_elements_by_xpath('/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "for i in search_ds:\n",
    "    if 'Data Scientist' in i.text:\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9c81df0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['Google', 'Microsoft Corporation', 'Goldman Sachs', 'Tekion', 'Amazon', 'Flipkart', 'Servicenow Software Development India', 'PayPal', 'Walmart', 'Arcesium']\n",
      "10\n",
      "[' 33 salaries', ' 271 salaries', ' 18 salaries', ' 33 salaries', ' 119 salaries', ' 63 salaries', ' 56 salaries', ' 28 salaries', ' 85 salaries', ' 56 salaries']\n"
     ]
    }
   ],
   "source": [
    "company_name = []\n",
    "total_salary_record = []\n",
    "company_tag = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "for i in company_tag:\n",
    "    company_name.append(i.text.split('\\n')[0])\n",
    "    total_salary_record.append(i.text.split('\\n')[1].replace('based on',''))\n",
    "company_name = company_name[:10]\n",
    "total_salary_record = total_salary_record[:10]\n",
    "print(len(company_name))\n",
    "print(company_name)\n",
    "print(len(total_salary_record))\n",
    "print(total_salary_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c9b22116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['₹ 31.8L', '₹ 23.9L', '₹ 23.0L', '₹ 21.1L', '₹ 20.9L', '₹ 20.6L', '₹ 20.4L', '₹ 20.1L', '₹ 19.9L', '₹ 19.3L']\n"
     ]
    }
   ],
   "source": [
    "Average_salary_record = []\n",
    "salary_tag = driver.find_elements_by_xpath('//p[@class=\"averageCtc\"]')\n",
    "for i in salary_tag:\n",
    "    Average_salary_record.append(i.text.split('\\n')[0])\n",
    "Average_salary_record = Average_salary_record[:10]\n",
    "print(len(Average_salary_record))\n",
    "print(Average_salary_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6fcaf36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['₹ 11.0L', '₹ 13.0L', '₹ 12.0L', '₹ 12.0L', '₹ 8.0L', '₹ 7.5L', '₹ 13.0L', '₹ 12.0L', '₹ 11.4L', '₹ 12.0L']\n",
      "10\n",
      "['₹ 65.0L', '₹ 45.0L', '₹ 34.0L', '₹ 33.0L', '₹ 45.0L', '₹ 31.0L', '₹ 28.0L', '₹ 31.0L', '₹ 32.5L', '₹ 34.0L']\n"
     ]
    }
   ],
   "source": [
    "minimum_salary = []\n",
    "maximum_salary = []\n",
    "salary_tag_min = driver.find_elements_by_xpath('//div[@class=\"salary-values\"]')\n",
    "for i in salary_tag_min:\n",
    "    minimum_salary.append(i.text.split('\\n')[0])\n",
    "    maximum_salary.append(i.text.split('\\n')[1])\n",
    "minimum_salary = minimum_salary[:10]\n",
    "print(len(minimum_salary))\n",
    "print(minimum_salary)\n",
    "print(len(maximum_salary))\n",
    "print(maximum_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ba5bf009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['1-3 yrs ', '1-4 yrs ', '2 yrs ', '2-4 yrs ', '1-4 yrs ', '1-4 yrs ', '2-4 yrs ', '1-2 yrs ', '1-4 yrs ', '1-2 yrs ']\n"
     ]
    }
   ],
   "source": [
    "Experience_required = []\n",
    "exp = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "for i in exp:\n",
    "    Experience_required.append(i.text.split('\\n')[-1].replace('exp',''))\n",
    "Experience_required = Experience_required[:10]\n",
    "print(len(Experience_required))\n",
    "print(Experience_required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "dda9b77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Total_salary_record</th>\n",
       "      <th>Minimum_salary</th>\n",
       "      <th>Average_salary_record</th>\n",
       "      <th>Maximum_salary</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>33 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 31.8L</td>\n",
       "      <td>₹ 65.0L</td>\n",
       "      <td>1-3 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>271 salaries</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 23.9L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>1-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>18 salaries</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "      <td>2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>33 salaries</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 21.1L</td>\n",
       "      <td>₹ 33.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>119 salaries</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 20.9L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>1-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>63 salaries</td>\n",
       "      <td>₹ 7.5L</td>\n",
       "      <td>₹ 20.6L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "      <td>1-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>56 salaries</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 20.4L</td>\n",
       "      <td>₹ 28.0L</td>\n",
       "      <td>2-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>28 salaries</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 20.1L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "      <td>1-2 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>85 salaries</td>\n",
       "      <td>₹ 11.4L</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 32.5L</td>\n",
       "      <td>1-4 yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arcesium</td>\n",
       "      <td>56 salaries</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 19.3L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "      <td>1-2 yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Company Total_salary_record Minimum_salary  \\\n",
       "0                                 Google         33 salaries        ₹ 11.0L   \n",
       "1                  Microsoft Corporation        271 salaries        ₹ 13.0L   \n",
       "2                          Goldman Sachs         18 salaries        ₹ 12.0L   \n",
       "3                                 Tekion         33 salaries        ₹ 12.0L   \n",
       "4                                 Amazon        119 salaries         ₹ 8.0L   \n",
       "5                               Flipkart         63 salaries         ₹ 7.5L   \n",
       "6  Servicenow Software Development India         56 salaries        ₹ 13.0L   \n",
       "7                                 PayPal         28 salaries        ₹ 12.0L   \n",
       "8                                Walmart         85 salaries        ₹ 11.4L   \n",
       "9                               Arcesium         56 salaries        ₹ 12.0L   \n",
       "\n",
       "  Average_salary_record Maximum_salary Experience_required  \n",
       "0               ₹ 31.8L        ₹ 65.0L            1-3 yrs   \n",
       "1               ₹ 23.9L        ₹ 45.0L            1-4 yrs   \n",
       "2               ₹ 23.0L        ₹ 34.0L              2 yrs   \n",
       "3               ₹ 21.1L        ₹ 33.0L            2-4 yrs   \n",
       "4               ₹ 20.9L        ₹ 45.0L            1-4 yrs   \n",
       "5               ₹ 20.6L        ₹ 31.0L            1-4 yrs   \n",
       "6               ₹ 20.4L        ₹ 28.0L            2-4 yrs   \n",
       "7               ₹ 20.1L        ₹ 31.0L            1-2 yrs   \n",
       "8               ₹ 19.9L        ₹ 32.5L            1-4 yrs   \n",
       "9               ₹ 19.3L        ₹ 34.0L            1-2 yrs   "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_data = pd.DataFrame()\n",
    "salary_data['Company'] = company_name\n",
    "salary_data['Total_salary_record'] = total_salary_record\n",
    "salary_data['Minimum_salary'] = minimum_salary\n",
    "salary_data['Average_salary_record'] = Average_salary_record\n",
    "salary_data['Maximum_salary'] = maximum_salary\n",
    "salary_data['Experience_required'] = Experience_required\n",
    "salary_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d6b1ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de1e190",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
